{"pages":[],"posts":[{"title":"Java线程的自述","text":"我是谁我是一个线程，一个底层的打工人。 总有人把我和进程搞混，但其实我和进程的区别很大。 进程是程序的一次执行，CPU的资源都是分发给进程而不是分发给我们线程，进程是资源分配的最小单位，一个进程可以包含很多向我这样的线程。 我们线程是CPU调度执行的最小单位，真正的打工人。 Java中的线程在Java里面，我的名字叫做java.lang.Thread。 需要注意的是，调用run方法和执行一个普通方法没有区别。想要真正的创建一个线程并启动，需要调用我的start方法。 有一点我必须告诉你，就是我也是有小弟的。 在JVM里面，我有一个JavaThread的小弟，他帮我联系操作系统的osthread线程。 调用我的start方法之后，具体的执行流程是这样的： 当然了，这个过程省略了很多细节，不过很明确的是，我和内核线程是一一对应的。 调度我就相当于调度内核线程，而调度内核线程需要在用户态和内核态之间切换，这个过程开销是非常大的。 所以，创建我成本是很高的，一定要慎重。 线程池和你们人类一样，我也有着精彩的一生，也会经历出生（创建）、奋斗（Running）、死亡（销毁）等过程，今天我主要和你讲述的是我打工奋斗的生活。 原来我是打零工的，有人需要我的时候就创建一个我，等我完成工作就把我销毁。 上面也提到过，我和内核线程是一对一的，创建和销毁的过程是非常消耗资源的，所以这样的成本非常高。 于是，有人就想了一个办法，开了一个公司，也就是你们说的线程池。 线程池公司统一管理调度我们线程。我们在线程池里面重复着等待工作——完成工作的步骤。 这样我就可以日复一日年复一年的重复打工了，这种提供了减少对象数量从而改善应用所需的对象结构的方式的模式，被你们人类叫做“享元模式”。 线程池公司有很多种，但都离不开这几个主要指标： corePoolSize：公司正式员工人数。 maximumPoolSize：正式工+临时工最大数量。 keepAliveTime：临时工多久没做事情会被开除。 unit：临时工没做事情会被开除的时间单位。 workQueue：公司业务接收部门。 threadFactory：行政部，负责招聘培训员工的。 handler：业务部接收业务到达上限了的处理方式。 阻塞队列线程池中的workQueue是一个阻塞队列，用于存放线程池未能及时处理执行的任务。 它的存在既解耦了任务的提交与执行，又能起到一个缓冲的作用。 阻塞队列有很多，下面我带你了解一下常见的阻塞队列。 ArrayBlockingQueue基于数组实现的有界阻塞队列，创建的时候需要指定容量。此类型的队列按照FIFO（先进先出）的规则对元素进行排序。 LinkedBlockingQueue基于链表实现阻塞队列，默认大小为Integer.MAX_VALUE。按照FIFO（先进先出）的规则对元素进行排序 SynchronousQueue一个不存储元素的阻塞队列。每一个put操作必须阻塞等待其他线程的take操作，take操作也必须等待其他线程的put操作。 PriorityBlockingQueue一个基于数组利用堆结构实现优先级效果的无界队列，默认自然序排序，也可以自己实现compareTo方法自定义排序规则。 DelayedWorkQueue一个实现了优先级队列功能且实现了延迟获取的无界队列，在创建元素时，可以指定多久多久才能在队列中获取当前元素。只有延时期满了后才能从队列中获取元素。 拒绝策略当任务队列满了之后，如果还有任务提交过来，会触发拒绝策略，常见的拒绝策略有： AbortPolicy：丢弃任务并抛出异常，默认该方式。 CallerRunsPolicy：由调用线程自己处理该任务。谁调用，谁处理。 DiscardPolicy：丢弃任务，但是不抛出异常。 DiscardOldestPolicy：抛弃任务队列中最旧的任务也就是最先加入队列的，再把这个新任务添加进去。先从任务队列中弹出最先加入的任务，空出一个位置，然后再次执行execute方法把任务加入队列。 当然，除了以上这几种拒绝策略，你也可以根据实际的业务场景和业务需求去自定义拒绝策略，只需要实现RejectedExecutionHander接口，自定义里面的rejectedExecution方法。 运行流程我们每个线程会被包装成Worker，线程池里面有一个HashSet存放Worker。 当有任务提交过来之后： 首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。 如果线程池中Worker的数量小于核心线程数，就会去创建一个新的线程，也就是招聘一个正式工让他执行任务。 如果Worker的数量大于或者等于核心线程数，就会把任务放到阻塞任务队列里面。 如果任务队列满了还有任务过来，如果临时工名额没有满（workerCount &lt; maximumPoolSize），就去招聘临时工让临时工执行任务。如果临时工名额都满了，触发任务拒绝策略。 总结而言，就是核心线程能干的事情尽量不去创建非核心线程，这是线程池很关键的一点。 有哪些线程池我有过四段工作经历，每段经历都有着精彩的故事。 SingleThreadExecutorSingleThreadExecutor是我加入的第一家线程池，这是一家创业公司，整个线程池就只有我一个线程。 所有的任务都由我干，而且任务队列是一个无界队列。就是说，打工的线程只有我一个，但是需求任务可以是无限多。 在需求任务很多的时候，经常出现任务处理不过来的情况，导致任务堆积，出现OOM。 但因为所有的活都是我干，没有繁琐的沟通成本，不需要处理线程同步的问题，这算是这种线程池的一个优点吧。 这种线程池适用于并发量不大且需要任务顺序执行的场景。 FixedThreadPool后来公司倒闭了，我又加入了一个叫FixedThreadPool的线程池。 FixedThreadPool和SingleThreadExecutor唯一不同的地方就是核心线程的数量，FixedThreadPool可以招收很多的打工线程。 在这里，我不再是孤军奋斗了，我有了一群共同打拼的小伙伴，大家一起完成任务，一起承担压力。 可这种线程池还是存在一个问题——任务队列是无界的，需求任务过多的话，还是会造成OOM。 这种线程池线程数固定，且不被回收，线程与线程池的生命周期同步的线程池，适用于任务量比较固定但耗时长的任务。 CachedThreadPool后来，为了离家更近，我离职了。加入了一家叫CachedThreadPool的线程池，进去之后，却发现这是一家外包公司。 这种线程池里面没有一个核心线程（正式工），一有需求就去招聘一个非核心线程（临时工）。 如果一个线程任务干完了之后，60秒之后没有新的任务就会被辞退。 这种线程池的任务队列采用的是SynchronousQueue，这个队列是无法插入任务的，一有任务就创建一个线程执行，如果并发高且任务耗时长，创建太多线程也是可能导致OOM的。所以CachedThreadPool比较适合任务量大但耗时少的任务。 ScheduleThreadPool经历了外面的风风雨雨，我觉得还是找份固定的工作比较可靠，于是我加入了一家叫做ScheduleThreadPool的国企。 在这里，工作比较的轻松，多数情况下，我只需要在固定的时间干固定的活。 任务忙不过来的时候，公司也会招聘一些临时工帮忙处理，临时工干完活就会被辞退。 综合来说，这类线程池适用于执行定时任务和具体固定周期的重复任务。由于采用的任务队列是DelayedWorkQueue无界队列，所以也是有OOM的风险的。 总结好了，关于线程的故事就告一段落了。关于线程池的应用实践，我们下次再聊。 文章开头的面试题在大部分在文中都能找到答案，对于没有提到的，这里做一个补充： 1. 线程池提交任务有哪几种方式？分别有什么区别？有execute和submit两种方式 execute只能提交Runnable类型的任务，无返回值。submit既可以提交Runnable类型的任务，也可以提交Callable类型的任务，会有一个类型为Future的返回值，但当任务类型为Runnable时，返回值为null。 execute在执行任务时，如果遇到异常会直接抛出，而submit不会直接抛出，只有在使用Future的get方法获取返回值时，才会抛出异常。 2. 线程池里面的线程执行异常了会怎么样？如果一个线程执行任务的过程中出现异常，那么这个线程对应的Worker会被移出线程池，该线程也会被销毁回收。 同时会通过指定的线程工厂创建一个线程，并封装成Worker放入线程池代替移除的Worker。 3. 核心线程能被回收吗？核心线程默认不会被回收。但是可以调用allowCoreThreadTimeOut让核心线程可以被回收。 需要注意的是，调用这个方法的线程池必须将keepAliveTime设置为大于0，否则会抛出异常。 4. 核心线程和非核心线程是如何区分的？核心线程和非核心线程是一个抽象概念，只是用于更好的表述线程池的运行逻辑，实际上都对应操作系统的osThread，都是重量级线程。 在新增Worker的时候，通过一个boolean表达是核心线程还是非核心线程，本质上两者没有什么不同。 5. 为什么阿里不允许使用 Executors 去创建线程池？FixedThreadPool 和 SingleThreadPool：允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 CachedThreadPool：允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 总结来说就是，使用Executors创建线程池会容易忽视线程池的一些属性，使用不当容易引起资源耗尽。 写在最后 这个世界上或许没有线程，又或许人人都是线程。 好了，今天的文章就到这里了。 最后，感谢你的阅读！ 我是CoderW，一个普通的程序员。 点个关注，我们下期再见！ 参考文章 https://mp.weixin.qq.com/s/baYuX8aCwQ9PP6k7TDl2Ww 《Java并发编程的艺术》 《深入理解Java虚拟机》","link":"/javathread/"},{"title":"深入汇编指令解析Java关键字volatile","text":"volatile是什么volatile关键字是Java提供的一种轻量级同步机制。它能够保证可见性和有序性，但是不能保证原子性 可见性对于volatile的可见性，先看看这段代码的执行 flag默认为true 创建一个线程A去判断flag是否为true，如果为true循环执行i++操作 两秒后，创建另一个线程B将flag修改为false 线程A没有感知到flag已经被修改成false了，不能跳出循环 这相当于啥呢？相当于你的女神和你说，你好好努力，年薪百万了就嫁给你，你听了之后，努力赚钱。3年之后，你年薪百万了，回去找你女神，结果发现你女神结婚了，她结婚的消息根本没有告诉你！难不难受？ 女神结婚可以不告诉你，可是Java代码中的属性都是存在内存中，一个线程的修改为什么另一个线程为什么不可见呢？这就不得不提到Java中的内存模型了，Java中的内存模型，简称JMM，JMM定义了线程和主内存之间的抽象关系，定义了线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量的副本，它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。 注意！JMM是一个屏蔽了不同操作系统架构的差异的抽象概念，只是一组Java规范。 了解了JMM，现在我们再回顾一下文章开头的那段代码，为什么线程B修改了flag线程A看到的还是原来的值呢？ 因为线程A复制了一份刚开始的flage=true到本地内存，之后线程A使用的flag都是这个复制到本地内存的flag。 线程B修改了flag之后，将flag的值刷新到主内存，此时主内存的flag值变成了false。 线程A是不知道线程B修改了flag，一直用的是本地内存的flag = true。 那么，如何才能让线程A知道flag被修改了呢？或者说怎么让线程A本地内存中缓存的flag无效，实现线程间可见呢？用volatile修饰flag就可以做到: 我们可以看到，用volatile修饰flag之后，线程B修改flag之后线程A是能感知到的，说明了volatile保证了线程同步之间的可见性。 重排序在阐述volatile有序性之前，需要先补充一些关于重排序的知识。 重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。 为什么要有重排序呢？简单来说，就是为了提升执行效率。为什么能提升执行效率呢？我们看下面这个例子： 可以看到重排序之后CPU实际执行省略了一个读取和写回的操作，也就间接的提升了执行效率。 有一点必须强调的是，上图的例子只是为了让读者更好的理解为什么重排序能提升执行效率，实际上Java里面的重排序并不是基于代码级别的，从代码到CPU执行之间还有很多个阶段，CPU底层还有一些优化，实际上的执行流程可能并不是上图的说的那样。不必过于纠结于此。 重排序可以提高程序的运行效率，但是必须遵循as-if-serial语义。as-if-serial语义是什么呢？简单来说，就是不管你怎么重排序，你必须保证不管怎么重排序，单线程下程序的执行结果不能被改变。 有序性上面我们已经介绍了Java有重排序情况，现在我们再来聊一聊volatile的有序性。 先看一个经典的面试题：为什么DDL（double check lock）单例模式需要加volatile关键字？ 因为singleton = new Singleton()不是一个原子操作，大概要经过这几个步骤： 分配一块内存空间 调用构造器，初始化实例 singleton指向分配的内存空间 实际执行的时候，可能发生重排序，导致实际执行步骤是这样的： 申请一块内存空间 singleton指向分配的内存空间 调用构造器，初始化实例 在singleton指向分配的内存空间之后，singleton就不为空了。但是在没有调用构造器初始化实例之前，这个对象还处于半初始化状态，在这个状态下，实例的属性都还是默认属性，这个时候如果有另一个线程调用getSingleton()方法时，会拿到这个半初始化的对象，导致出错。 而加volatile修饰之后，就会禁止重排序，这样就能保证在对象初始化完了之后才把singleton指向分配的内存空间，杜绝了一些不可控错误的产生。volatile提供了happens-before保证，对volatile变量的写入happens-before所有其他线程后续对的读操作。 原理从上面的DDL单例用例来看，在并发情况下，重排序的存在会导致一些未知的错误。而加上volatile之后会防止重排序，那volatile是如何禁止重排序呢？ 为了实现volatile的内存语义，JMM会限制特定类型的编译器和处理器重排序，JMM会针对编译器制定volatile重排序规则表： 总结来说就是： 第二个操作是volatile写，不管第一个操作是什么都不会重排序 第一个操作是volatile读，不管第二个操作是什么都不会重排序 第一个操作是volatile写，第二个操作是volatile读，也不会发生重排序 如何保证这些操作不会发送重排序呢？就是通过插入内存屏障保证的，JMM层面的内存屏障分为读（load）屏障和写（Store）屏障，排列组合就有了四种屏障。对于volatile操作，JMM内存屏障插入策略： 在每个volatile写操作的前面插入一个StoreStore屏障 在每个volatile写操作的后面插入一个StoreLoad屏障 在每个volatile读操作的后面插入一个LoadLoad屏障 在每个volatile读操作的后面插入一个LoadStore屏障 上面的屏障都是JMM规范级别的，意思是，按照这个规范写JDK能保证volatile修饰的内存区域的操作不会发送重排序。 在硬件层面上，也提供了一系列的内存屏障来提供一致性的能力。拿X86平台来说，主要提供了这几种内存屏障指令： lfence指令：在lfence指令前的读操作当必须在lfence指令后的读操作前完成，类似于读屏障 sfence指令：在sfence指令前的写操作当必须在sfence指令后的写操作前完成，类似于写屏障 mfence指令： 在mfence指令前的读写操作当必须在mfence指令后的读写操作前完成，类似读写屏障。 JMM规范需要加这么多内存屏障，但实际情况并不需要加这么多内存屏障。以我们常见的X86处理器为例，X86处理器不会对读-读、读-写和写-写操作做重排序，会省略掉这3种操作类型对应的内存屏障，仅会对写-读操作做重排序。所以volatile写-读操作只需要在volatile写后插入StoreLoad屏障。在《The JSR-133 Cookbook for Compiler Writers》中，也很明确的指出了这一点： 而在x86处理器中，有三种方法可以实现实现StoreLoad屏障的效果，分别为： mfence指令：上文提到过，能实现全能型屏障，具备lfence和sfence的能力。 cpuid指令：cpuid操作码是一个面向x86架构的处理器补充指令，它的名称派生自CPU识别，作用是允许软件发现处理器的详细信息。 lock指令前缀：总线锁。lock前缀只能加在一些特殊的指令前面。 实际上HotSpot关于volatile的实现就是使用的lock指令，只在volatile标记的地方加上带lock前缀指令操作，并没有参照JMM规范的屏障设计而使用对应的mfence指令。 加上-XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XcompJVM参数再次执行main方法，在打印的汇编码中，我们也可以看到有一个lock addl $0x0,(%rsp)的操作。 在源码中也可以得到验证： lock addl $0x0,(%rsp)后面的addl $0x0,(%rsp)其实是一个空操作。add是加的意思，0x0是16进制的0，rsp是一种类型寄存器，合起来就是把寄存器的值加0，加0是不是等于什么都没有做？这段汇编码仅仅是lock指令的一个载体而已。其实上文也有提到过，lock前缀只能加在一些特殊的指令前面，add就是其中一个指令。 至于Hotspot为什么要使用lock指令而不是mfence指令，按照我的理解，其实就是省事，实现起来简单。因为lock功能过于强大，不需要有太多的考虑。而且lock指令优先锁缓存行，在性能上，lock指令也没有想象中的那么差，mfence指令更没有想象中的好。所以，使用lock是一个性价比非常高的一个选择。而且，lock也有对可见性的语义说明。 在《IA-32架构软件开发人员手册》的指令表中找到lock： 我不打算在这里深入阐述lock指令的实现原理和细节，这很容易陷入堆砌技术术语中，而且也超出了本文的范围，有兴趣的可以去看看《IA-32架构软件开发人员手册》。 我们只需要知道lock的这几个作用就可以了： 确保后续指令执行的原子性。在Pentium及之前的处理器中，带有lock前缀的指令在执行期间会锁住总线，使得其它处理器暂时无法通过总线访问内存，很显然，这个开销很大。在新的处理器中，Intel使用缓存锁定来保证指令执行的原子性，缓存锁定将大大降低lock前缀指令的执行开销。 禁止该指令与前面和后面的读写指令重排序。 把写缓冲区的所有数据刷新到内存中。 总结来说，就是lock指令既保证了可见性也保证了原子性。 重要的事情再说一遍，是lock指令既保证了可见性也保证了原子性，和什么缓冲一致性协议啊，MESI什么的没有一点关系。 为了不让你把缓存一致性协议和JMM混淆，在前面的文章中，我特意没有提到过缓存一致性协议，因为这两者本不是一个维度的东西，存在的意义也不一样，这一部分，我们下次再聊。 总结全文重点是围绕volatile的可见性和有序性展开的，其中花了不少的部分篇幅描述了一些计算机底层的概念，对于读者来说可能过于无趣，但如果你能认真看完，我相信你或多或少也会有一点收获。 不去深究，volatile只是一个普通的关键字。深入探讨，你会发现volatile是一个非常重要的知识点。volatile能将软件和硬件结合起来，想要彻底弄懂，需要深入到计算机的最底层。但如果你做到了。你对Java的认知一定会有进一步的提升。 只把眼光放在Java语言，似乎显得非常局限。发散到其他语言，C语言，C++里面也都有volatile关键字。我没有看过C语言，C++里面volatile关键字是如何实现的，但我相信底层的原理一定是相通的。 写在最后本着对每一篇发出去的文章负责的原则，文中涉及知识理论，我都会尽量在官方文档和权威书籍找到并加以验证。但即使这样，我也不能保证文中每个点都是正确的，如果你发现错误之处，欢迎指出，我会对其修正。 创作不易，你的正反馈对我来说非常重要！点个赞，点个再看，点个关注甚至评论区发送一条666都是对我最大的支持！ 我是CoderW，一个普通的程序员。 谢谢你的阅读，我们下期再见！ 个人公众号“CoderW”，欢迎并十分感谢你的关注 参考资料 JSR-133: http://gee.cs.oswego.edu/dl/jmm/cookbook.html 《Java并发编程的艺术》 《深入理解Java虚拟机》第三版 《IA-32+架构软件开发人员手册》","link":"/volatile/"},{"title":"来自未来的技术——ZGC垃圾回收器","text":"ZGC介绍ZGC（The Z Garbage Collector）是JDK 11中推出的一款追求极致低延迟的实验性质的垃圾收集器，它曾经设计目标包括： 停顿时间不超过10ms； 停顿时间不会随着堆的大小，或者活跃对象的大小而增加； 支持8MB~4TB级别的堆（未来支持16TB）。 当初，提出这个目标的时候，有很多人都觉得设计者在吹牛逼。 但今天看来，这些“吹下的牛逼”都在一个个被实现。 基于最新的JDK15来看，“停顿时间不超过10ms”和“支持16TB的堆”这两个目标已经实现，并且官方明确指出JDK15中的ZGC不再是实验性质的垃圾收集器，且建议投入生产了。 本文会从ZGC的设计思路出发，讲清楚为何ZGC能在低延时场景中的应用中有着如此卓越的表现。 核心技术多重映射为了能更好的理解ZGC的内存管理，我们先看一下这个例子： 你在你爸爸妈妈眼中是儿子，在你女朋友眼中是男朋友。在全世界人面前就是最帅的人。你还有一个名字，但名字也只是你的一个代号，并不是你本人。将这个关系画一张映射图表示： 在你爸爸的眼中，你就是儿子； 在你女朋友的眼中，你就说男朋友； 站在全世界角度来看，你就说世界上最帅的人； 假如你的名字是全世界唯一的，通过“你的名字”、“你爸爸的儿子”、“你女朋友的男朋友”，“世界上最帅的人”最后定位到的都是你本人。 现在我们再来看看ZGC的内存管理。 ZGC为了能高效、灵活地管理内存，实现了两级内存管理：虚拟内存和物理内存，并且实现了物理内存和虚拟内存的映射关系。这和操作系统中虚拟地址和物理地址设计思路基本一致。 当应用程序创建对象时，首先在堆空间申请一个虚拟地址，ZGC同时会为该对象在Marked0、Marked1和Remapped三个视图空间分别申请一个虚拟地址，且这三个虚拟地址对应同一个物理地址。 图中的Marked0、Marked1和Remapped三个视图是什么意思呢？ 对照上面的例子，这三个视图分别对应的就是”你爸爸眼中”，“你女朋友的眼中”，“全世界人眼中”。 而三个视图里面的地址，都是虚拟地址，对应的是“你爸爸眼中的儿子”，“你女朋友眼中的男朋友”…… 最后，这些虚地址都能定位到一个物理地址，这个物理地址对应上面例子中的“你本人”。 用一段简单的Java代码表示就是这样的： 在ZGC中这三个空间在同一时间点有且仅有一个空间有效。 为什么这么设计呢？这就是ZGC的高明之处，利用虚拟空间换时间，这三个空间的切换是由垃圾回收的不同阶段触发的，通过限定三个空间在同一时间点有且仅有一个空间有效高效的完成GC过程的并发操作，具体实现会后面讲ZGC并发处理算法的部分再详细描述。 染色指针在讲ZGC并发处理算法之前，还需要补充一个知识点——染色指针。 我们都知道，之前的垃圾收集器都是把GC信息（标记信息、GC分代年龄..）存在对象头的Mark Word里。举个例子： 如果某个人是个垃圾人，就在这个人的头上盖一个“垃圾”的章；如果这个人不是垃圾了，就把这个人头上的“垃圾”印章洗掉。 而ZGC是这样做的： 如果某个人是垃圾人。就在这个人的身份证信息里面标注这个人是个垃圾，以后不管这个人在哪刷身份证，别人都知道他是个垃圾人了。也许哪一天，这个人醒悟了不再是垃圾人了，就把这个人身份证里面的“垃圾”标志去掉。 在这例子中，“这个人”就是一个对象，而“身份证”就是指向这个对象的指针。 ZGC将信息存储在指针中，这种技术有一个高大上的名字——染色指针（Colored Pointer）。 在64位的机器中，对象指针是64位的。 ZGC使用64位地址空间的第0~43位存储对象地址，2^44 = 16TB，所以ZGC最大支持16TB的堆。 而第44~47位作为颜色标志位，Marked0、Marked1和Remapped代表三个视图标志位，Finalizable表示这个对象只能通过finalizer才能访问。 第48~63位固定为0没有利用。 读屏障读屏障是JVM向应用代码插入一小段代码的技术。当应用线程从堆中读取对象引用时，就会执行这段代码。千万不要把这个读屏障和Java内存模型里面的读屏障搞混了，两者根本不是同一个东西，ZGC中的读屏障更像是一种AOP技术，在字节码层面或者编译代码层面给读操作增加一个额外的处理。 读屏障实例： 123456Object o = obj.FieldA // 从堆中读取对象引用，需要加入读屏障&lt;load barrier needed here&gt; Object p = o // 无需加入读屏障，因为不是从堆中读取引用o.dosomething() // 无需加入读屏障，因为不是从堆中读取引用int i = obj.FieldB // 无需加入读屏障，因为不是对象引用 ZGC中读屏障的代码作用： GC线程和应用线程是并发执行的，所以存在应用线程去A对象内部的引用所指向的对象B的时候，这个对象B正在被GC线程移动或者其他操作，加上读屏障之后，应用线程会去探测对象B是否被GC线程操作，然后等待操作完成再读取对象，确保数据的准确性。具体的探测和操作步骤如下： 这样会影响程序的性能吗？ 会。据测试，最多百分之4的性能损耗。但这是ZGC并发转移的基础，为了降低STW，设计者认为这点牺牲是可接受的。 ZGC并发处理算法ZGC并发处理算法利用全局空间视图的切换和对象地址视图的切换，结合SATB算法实现了高效的并发。 以上所有的铺垫，都是为了讲清楚ZGC的并发处理算法，在一些博文上，都说染色指针和读屏障是ZGC的核心，但都没有讲清楚两者是如何在算法里面被利用的，我认为，ZGC的并发处理算法才是ZGC的核心，染色指针和读屏障只不过是为算法服务而已。 ZGC的并发处理算法三个阶段的全局视图切换如下： 初始化阶段：ZGC初始化之后，整个内存空间的地址视图被设置为Remapped 标记阶段：当进入标记阶段时的视图转变为Marked0（以下皆简称M0）或者Marked1（以下皆简称M1） 转移阶段：从标记阶段结束进入转移阶段时的视图再次设置为Remapped 标记阶段标记阶段全局视图切换到M0视图。因为应用程序和标记线程并发执行，那么对象的访问可能来自标记线程和应用程序线程。 在标记阶段结束之后，对象的地址视图要么是M0，要么是Remapped。 如果对象的地址视图是M0，说明对象是活跃的； 如果对象的地址视图是Remapped，说明对象是不活跃的，即对象所使用的内存可以被回收。 当标记阶段结束后，ZGC会把所有活跃对象的地址存到对象活跃信息表，活跃对象的地址视图都是M0。 转移阶段转移阶段切换到Remapped视图。因为应用程序和转移线程也是并发执行，那么对象的访问可能来自转移线程和应用程序线程。 至此，ZGC的一个垃圾回收周期中，并发标记和并发转移就结束了。 为何要设计M0和M1我们提到在标记阶段存在两个地址视图M0和M1，上面的算法过程显示只用到了一个地址视图，为什么设计成两个？简单地说是为了区别前一次标记和当前标记。 ZGC是按照页面进行部分内存垃圾回收的，也就是说当对象所在的页面需要回收时，页面里面的对象需要被转移，如果页面不需要转移，页面里面的对象也就不需要转移。 如图，这个对象在第二次GC周期开始的时候，地址视图还是M0。如果第二次GC的标记阶段还切到M0视图的话，就不能区分出对象是活跃的，还是上一次垃圾回收标记过的。这个时候，第二次GC周期的标记阶段切到M1视图的话就可以区分了，此时这3个地址视图代表的含义是： M1：本次垃圾回收中识别的活跃对象。 M0：前一次垃圾回收的标记阶段被标记过的活跃对象，对象在转移阶段未被转移，但是在本次垃圾回收中被识别为不活跃对象。 Remapped：前一次垃圾回收的转移阶段发生转移的对象或者是被应用程序线程访问的对象，但是在本次垃圾回收中被识别为不活跃对象。 现在，我们可以回答“使用地址视图和染色指针有什么好处”这个问题了 使用地址视图和染色指针可以加快标记和转移的速度。以前的垃圾回收器通过修改对象头的标记位来标记GC信息，这是有内存存取访问的，而ZGC通过地址视图和染色指针技术，无需任何对象访问，只需要设置地址中对应的标志位即可。这就是ZGC在标记和转移阶段速度更快的原因。 当GC信息不再存储在对象头上时而存在引用指针上时，当确定一个对象已经无用的时候，可以立即重用对应的内存空间，这是把GC信息放到对象头所做不到的。 ZGC步骤ZGC采用的是标记-复制算法，标记、转移和重定位阶段几乎都是并发的，ZGC垃圾回收周期如下图所示： ZGC只有三个STW阶段：初始标记，再标记，初始转移。 其中，初始标记和初始转移分别都只需要扫描所有GC Roots，其处理时间和GC Roots的数量成正比，一般情况耗时非常短； 再标记阶段STW时间很短，最多1ms，超过1ms则再次进入并发标记阶段。即，ZGC几乎所有暂停都只依赖于GC Roots集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。与ZGC对比，G1的转移阶段完全STW的，且停顿时间随存活对象的大小增加而增加。 ZGC的发展ZGC诞生于JDK11，经过不断的完善，JDK15中的ZGC已经不再是实验性质的了。 从只支持Linux/x64，到现在支持多平台；从不支持指针压缩，到支持压缩类指针….. 在JDK16，ZGC将支持并发线程栈扫描（Concurrent Thread Stack Scanning），根据SPECjbb2015测试结果，实现并发线程栈扫描之后，ZGC的STW时间又能降低一个数量级，停顿时间将进入毫秒时代。 ZGC已然是一款优秀的垃圾收集器了，它借鉴了Pauseless GC，也似乎在朝着C4 GC的方向发展——引入分代思想。 Oracle的努力，让我们开发者看到了商用级别的GC“飞入寻常百姓家”的希望，随着JDK的发展，我相信在未来的某一天，JVM调优这种反人类的操作将不复存在，底层的GC会自适应各种情况自动优化。 ZGC确实是Java的最前沿的技术，但在G1都没有普及的今天，谈论ZGC似乎为时过早。但也许我们探讨的不是ZGC，而是ZGC背后的设计思路。 希望你能有所收获！ 写在最后为了对每一篇发出去的文章负责，力求准确，我一般是参考官方文档和业界权威的书籍，有些时候，还需要看一些论文，看一部分源代码。而官方文档和论文一般都是英文，对于一个英语四级只考了456分的人来说，非常艰难，整个过程都是谷歌翻译和有道词典陪伴着我的。因为一些专业术语翻译的不够准确，还需要英文和翻译对照慢慢理解。 但即使这样，也难免会有纰漏，如果你发现了，欢迎提出，我会对其修正。 你的正反馈对我来说非常重要，点个赞，点个关注都是对我最大的支持！ 如果你有什么想和我交流的，可以关注我的微信公众号“CoderW”，非常欢迎并感谢您的关注！ 谢谢您的阅读，我们下期再见！ 参考资料 https://mp.weixin.qq.com/s/ag5u2EPObx7bZr7hkcrOTg 《新一代垃圾回收器ZGC设计与实现》","link":"/zgc/"},{"title":"用爬虫分析了2020年一年的热搜，我发现了什么？","text":"前言2020年是艰难的一年，但即使再难，也都过去了。 分析一下2020年的新闻热搜，可以大致了解网民都在关注什么。 微博热搜以娱乐为主，头条的热搜更偏向民生与时事。今天，我们先分析分析微博一整年的热搜。 数据抓取由于微博平台不能查看历史热搜，本文所有的数据都是从云合数据旗下的一个热搜榜抓取的，具体地址见文末。 抓取数据的代码是用Python写的，代码非常简单，就是模拟请求和数据统计两个部分。 抓取到了从2020年1月1日到2020年12月31日一共35901条数据，将抓取的数据存入Excel，数据格式如下图： 数据分析用pyecharts做可视化分析，先将所有的热搜数据按照热度做成一个词云。 “词云”是对海量文字内容中出现频率较高的视觉突出，即出现越多的“关键词”字体越大。这里用热度替代了出现次数 结合微博热搜话题搜索量TOP10，哪些热搜热度高就一目了然了。 罗志祥的分手引爆微博，两条热搜霸占全年热搜榜前二名，搜索指数加起来超过了5700万。要知道，鹿晗官宣和关晓彤在一起那一条热搜也只有1700多万搜索指数。 美国总统特朗普从看不起新冠，到最后夫妻双双确诊，打脸来的不要太快。“特朗普夫妇确诊新冠”的新闻也曾引爆微博甚至全球。 在前十榜单里面，“李文亮医生去世”和“李文亮仍在抢救”这两条热搜引人注目。 李文亮医生的事迹在当时引起了一阵轰动，一年的时间快要过去了，“李文亮”这个名字也慢慢不被人们提起，后人也许也不会知道这段故事。但人们不提，不代表忘记，互联网也是有记忆的，每当回忆起这次疫情，李文亮医生依旧站在那里。让我们向英雄致敬！ 热词回顾一年的热搜，和疫情相关的词汇出现的比较高频，“抗疫”成为了2020年中国甚至世界的主旋律。 2020年中美关系因美方一意孤行而比较紧张，加上美国疫情的不可控发展，“美国”和“特朗普”也频频登上热搜。 我还生成了“道歉”，“帅”，“结婚”，“分手”，“心疼”等关键字词云，大部分都是和娱乐圈相关的，今天你道歉，明天我发声。我的感觉就是，贵圈真乱。 人名出现次数排行榜统计了上热搜次数最多的前40个人。大部分都是娱乐圈的，其中周杰伦是榜中唯一一个没有开通微博的明星。 美国现总统特朗普和下任总统拜登因为选举和美国疫情不可控等因素频频上热搜，特朗普更是差不多平均一天上一次热搜。 获颁“共和国勋章”的敢医敢言的钟南山2020年上了196次热搜，从非典到新冠，攸关生命的大考，他从不缺位，向钟老致敬。 通过《陈情令》爆火的王一博和肖战，分别排在第四名和第六名。 有意思是，从2011年《宫》播出之后，杨幂每年上热搜次数就没有跌出过前10。 2020年，是直播带货蓬勃发展的一年，李佳琦和薇娅两个带货之王也频频登上热搜，甚至李佳琦以103次的成绩排到了第八名。 归国四子黄子韬、鹿晗、吴亦凡和张艺兴也依然保持热度，都有着比较靠前的排名。 2020年湖人队民宿科比坠机身亡，因此也上了69次热搜，R.I.P。 不开通微博的周董周杰伦，凭借自己的实力和强大的粉丝群体，强行上了59次热搜，是为数不多不靠炒作就能登上这个榜单的明星了。 最近一个月才大火的丁真，就以47次热搜的成绩登上排行榜，同时丁真也是12月上热搜次数最多的人。 总结 2020年微博热搜主旋律——抗疫 2020年上微博热搜次数最多的人——特朗普 2020年上微博热搜次数最多的娱乐明星——易烊千玺 2020年热度最高的微博热搜——罗志祥周扬青分手 以上所有的数据都基于热搜平台，一切信息都可以在平台查询。 写到这里，如果你问“买热搜”真的存在吗？ 我会告诉你，“买热搜”真的存在。我分析了几年的微博热搜数据，确实发现了一些问题，有些热搜非常莫名其妙，热度来得快去的也快，再结合一下其他平台的数据就能容易分析出这个热搜的真实性了。 但如果你问我有哪些明星买了热搜，我不能告诉你，为什么呢？因为我告诉你我的号就没了。 如果你实在有兴趣，公众号后台回复“热搜”，我会给你一份2020一整年的微博热搜数据Excel，你可以自己去慢慢分析。 写在最后以上所有的数据都基于热搜平台，一切信息都可以在平台查询。 本人才疏学浅，如有错误欢迎指出！ 最后，感谢您的阅读。 您的点赞和转发都是对我最大的支持，十分欢迎并感谢您的关注。 本文所有的资料和源码关注公众号‘CoderW’回复‘热搜’即可获取 热搜平台：https://www.enlightent.cn/research/rank/weiboSearchRank 参考文章: https://mp.weixin.qq.com/s/BD1rqPCQvhYP4i4bef_BAg。","link":"/resou/"}],"tags":[{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"数据分析","slug":"数据分析","link":"/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"categories":[{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"JVM","slug":"JVM","link":"/categories/JVM/"},{"name":"Python","slug":"Python","link":"/categories/Python/"}]}