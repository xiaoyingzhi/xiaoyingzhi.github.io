{"pages":[],"posts":[{"title":"javalife","text":"生活不可能像你想象得那么好，但也不会像你想象得那么糟。 我觉得人的脆弱和坚强都超乎自己的想象。 有时，我可能脆弱得一句话就泪流满面；有时，也发现自己咬着牙走了很长的路。 大学旁边的神龙塔和大一宿舍 ——都拍摄于大学开学第一天 选专业我是一个很普通的人，考了一个很普通的大学。 但庆幸的是，我在大学认识了一群不普通的人。感谢他们的出现，让我的大学过的并不普通。 我的大学专业是软件工程，之所以选这个专业，是因为当时我喜欢玩游戏，而当时的我以为这个专业就是做游戏的。 初入大学刚进大学的时候，我对什么都充满好奇，什么都想去尝试。 尝试过ACM，后面因为没有耐心放弃了。 尝试过加入一些社团，因为一些原因没去了。 后面学习也落下了，成了一个网瘾少年。 我虽然五音不全，但那个时候，仍然喜欢唱歌，那时候的一个乐趣之一就是大家围在我们的宿舍里面唱歌，海南哥阿斌的那一首《有何不可》到现在还让我印象深刻。 16年的时候，参加了学校的红歌赛，我们的参赛曲目是《国家》，最后拿了一个三等奖。只要一听到这首歌的前奏，就会想起当年那呆呆的学唱歌的样子，直到现在，我还记得这首歌的和声部分该怎么唱。 冬天的时候，一顿宿舍火锅是少不了的。 编程启蒙大三的时候，我突然意识到自己不能再这样下去了，于是我开始认真学习。 在学习Java的时候，我照着教材上面的用例，一行一行代码的敲，一遍一遍的练习， 最后我用Java做出了自己的第一个小程序——一个简单的Swing学生管理系统，那是我第一次真真切切的感觉到了编程的乐趣。 现在回看，这个系统写的太过于粗糙。但是，在我做过的项目和系统之中，这个系统一直是我最喜欢的。这些年来，我一直把它放在我的GitHub主页的第一个位置。 那一年，我靠自己拿到了奖学金。 那一年，和兄弟们一起吃了很多好吃的，一起逛了很多次神龙城，一起去了很多地方。 日出——拍摄于衡山 实习大三的暑假，我没有跟着学校的统一安排实习，而是自己投简历找个了一个实习工作。我想去外面看一下 为了实习，我买了一台联想的笔记本，我记得很清楚，电脑是花了5479买的，我爸微信给我转的5500。 去广州那天，是爸爸开车把我从家里送到高铁站的，一路上，妈妈叮嘱我的是照顾好自己，爸爸叮嘱我的是做人要脚踏实地。 检票通道的开启，也代表着我职业生涯的开启。那一年，我21岁。 当时的实习工资是1500不包吃不包住。 那时候真的穷，又不想问家里要钱，下午去租房的时候，对房子唯一的要求就是便宜。 在公司附近的一个城中村，我看着墙上的租房广告一个一个电话的打，一间房一间房的看。房子很多，但可以月租的都很贵，稍微便宜一点的都要求租三个月起步。 在最后，去一个房东奶奶家去看房的时候，她看我是学生，答应了我租两个月，一个月350，一共700。而且还没有收我押金。 房间很简单，是一个老式的筒子楼，房间里面就一张床，一个老式的电脑桌，没有空调和其他任何电器。 房东借给了我一个风扇，我在隔壁的小超市买了被子、凉席和一些生活用品，搞了一下午的卫生，也算是安顿下来了。 后面的实习生活，认识了佳哥、泉哥和翔哥。佳哥是湖南岳阳的，很逗比也很热心的一个人。泉哥广西人，一口广西粤语是相当标准。翔哥厦门人，年纪不大，却很稳重，去年结婚了。他们三个很照顾我，不管是技术上还是职场上都教会了我很多。 那段时间，每天下班之后，我都会蹭着隔壁的WiFi，光子膀子，坐在电脑桌面前学习。 天气太热，没有空调，就把风扇开到最大对着吹，身上汗多了就冲个冷水澡继续，每天就这样学到凌晨两三点。然后倒头就睡，第二天热醒来就爬起来去上班。 当时租的房子就在马路边上，楼下有两个垃圾桶，每天晚上都有很多动物的声音，有狗、猫、老鼠。因为我住的是二楼，听得是清清楚楚。 最让我头皮发麻的是有一次，两只壁虎爬到我的房间，打又打不到，赶又赶不跑。那天晚上我一晚上都没有睡好，脑海中浮现了一万种在我睡着时壁虎爬到我身上的情形。对于一个看到这种爬行动物就不舒服的我，简直就是折磨。 这样的生活持续了两个多月。 离职那天拍的公司所在的大楼 实习完回家，爸妈来高铁站接我，看到爸妈之后就止不住的想哭。回家吃到妈妈做的饭菜之后真的就哭得稀里哗啦的。 那天晚上躺在家里的大床上久久不能入眠。 实验室实习完回了趟家然后就马上去了满院长带的大数据组实验室。 在这里，我认识了一群真挚的朋友。大家来自不同的专业，但为了同一个想法和目的去努力。 谢谢他们的信任和支持，能让我毫无顾忌的去设计一些功能。过程中换了开发工具，重构了三次项目。最后实现了微信小程序落地，监控平台落地和大数据分析平台落地。 那段时间是不知道辛苦的，每天除了吃饭就一直呆在实验室，九到十点才回宿舍，每次都是阿旺骑着他的快要散架的小摩托把我们一个个送到宿舍。 那段时间是快乐的，不断的优化项目，重构项目，将自己的想法或者想用的技术加进去，是非常有成就感的。 在实验室拍的学校 秋招在有了实习的历练和实验室的项目经验之后，秋招对我来说也总算没有那么艰难和遥远了。 我大大小小拿了18个offer。有离家近的又离家远的。 父母在，不远游，游必有方。 最后决定离开自己的舒适区，去北京看一看，闯一闯。 毕业季毕业聚餐后，我们去了KTV，最后一首歌唱的是《我的好兄弟》。唱着唱着，平时大大咧咧的君总哭成了一个傻逼。那是大学四年，我第一次见君总流泪。 我们租了一个共享汽车，在送强哥回去的时候，车上还有说有笑。在下车送他进站的时候，我们合了一张影。 那也是大学四年，我第一次见强哥流泪。 毕业时，我们相约再见。2020年，我们再见长沙。 今天十一假，我们从上海、北京、杭州、南京、广州、深圳出发，相聚长沙。 时间太短，说不出再见，离别长沙的时候，我发了下面朋友圈。 很珍惜有一群这样的朋友，开心的时候可以互相装逼凡尔赛，不开心的时候可以互相吐槽聊人生。 总结回看那几年，满满的都是意气风发。 再回顾大学那几年走过的路，多多少少有点曲折，但也还算安稳。 感谢这一路来帮助过我的人，因为他们的帮忙，让我这一路简单的不少。 努力生活，用文字记录生活，不希望来年回看今朝的时候，只能用“普普通通，平平淡淡”八个字概括。 “感恩过去，无畏将来”，这是我20岁生日送给自己的八个字。 我希望自己谨记这八个字，心怀感恩，努力生活。 写在最后这段故事写了很久时间，原因是每次写到十一二点钟的时候，就变成了一个“诗人”，写故事变成了写鸡汤。白天的时候觉得太矫情又都删了，最后从一万字删到了5000多字。 关于北京的生活，我没有提及，故事太长，不再单身。我觉得值得单独来讲。 好了，今天就到这里了。 文笔虽烂，但喜欢分享，有时分享技术有时分享生活。 我是CoderWang，一个有温度的Java程序员。 我们下期再见！ 更多精彩微信公众号搜索“CoderW”，我们一起进步！ 如果可以，点赞、加关注，谢谢你！","link":"/javalife/"},{"title":"Java线程的自述","text":"我是谁我是一个线程，一个底层的打工人。 总有人把我和进程搞混，但其实我和进程的区别很大。 进程是程序的一次执行，CPU的资源都是分发给进程而不是分发给我们线程，进程是资源分配的最小单位，一个进程可以包含很多向我这样的线程。 我们线程是CPU调度执行的最小单位，真正的打工人。 Java中的线程在Java里面，我的名字叫做java.lang.Thread。 需要注意的是，调用run方法和执行一个普通方法没有区别。想要真正的创建一个线程并启动，需要调用我的start方法。 有一点我必须告诉你，就是我也是有小弟的。 在JVM里面，我有一个JavaThread的小弟，他帮我联系操作系统的osthread线程。 调用我的start方法之后，具体的执行流程是这样的： 当然了，这个过程省略了很多细节，不过很明确的是，我和内核线程是一一对应的。 调度我就相当于调度内核线程，而调度内核线程需要在用户态和内核态之间切换，这个过程开销是非常大的。 所以，创建我成本是很高的，一定要慎重。 线程池和你们人类一样，我也有着精彩的一生，也会经历出生（创建）、奋斗（Running）、死亡（销毁）等过程，今天我主要和你讲述的是我打工奋斗的生活。 原来我是打零工的，有人需要我的时候就创建一个我，等我完成工作就把我销毁。 上面也提到过，我和内核线程是一对一的，创建和销毁的过程是非常消耗资源的，所以这样的成本非常高。 于是，有人就想了一个办法，开了一个公司，也就是你们说的线程池。 线程池公司统一管理调度我们线程。我们在线程池里面重复着等待工作——完成工作的步骤。 这样我就可以日复一日年复一年的重复打工了，这种提供了减少对象数量从而改善应用所需的对象结构的方式的模式，被你们人类叫做“享元模式”。 线程池公司有很多种，但都离不开这几个主要指标： corePoolSize：公司正式员工人数。 maximumPoolSize：正式工+临时工最大数量。 keepAliveTime：临时工多久没做事情会被开除。 unit：临时工没做事情会被开除的时间单位。 workQueue：公司业务接收部门。 threadFactory：行政部，负责招聘培训员工的。 handler：业务部接收业务到达上限了的处理方式。 阻塞队列线程池中的workQueue是一个阻塞队列，用于存放线程池未能及时处理执行的任务。 它的存在既解耦了任务的提交与执行，又能起到一个缓冲的作用。 阻塞队列有很多，下面我带你了解一下常见的阻塞队列。 ArrayBlockingQueue基于数组实现的有界阻塞队列，创建的时候需要指定容量。此类型的队列按照FIFO（先进先出）的规则对元素进行排序。 LinkedBlockingQueue基于链表实现阻塞队列，默认大小为Integer.MAX_VALUE。按照FIFO（先进先出）的规则对元素进行排序 SynchronousQueue一个不存储元素的阻塞队列。每一个put操作必须阻塞等待其他线程的take操作，take操作也必须等待其他线程的put操作。 PriorityBlockingQueue一个基于数组利用堆结构实现优先级效果的无界队列，默认自然序排序，也可以自己实现compareTo方法自定义排序规则。 DelayedWorkQueue一个实现了优先级队列功能且实现了延迟获取的无界队列，在创建元素时，可以指定多久多久才能在队列中获取当前元素。只有延时期满了后才能从队列中获取元素。 拒绝策略当任务队列满了之后，如果还有任务提交过来，会触发拒绝策略，常见的拒绝策略有： AbortPolicy：丢弃任务并抛出异常，默认该方式。 CallerRunsPolicy：由调用线程自己处理该任务。谁调用，谁处理。 DiscardPolicy：丢弃任务，但是不抛出异常。 DiscardOldestPolicy：抛弃任务队列中最旧的任务也就是最先加入队列的，再把这个新任务添加进去。先从任务队列中弹出最先加入的任务，空出一个位置，然后再次执行execute方法把任务加入队列。 当然，除了以上这几种拒绝策略，你也可以根据实际的业务场景和业务需求去自定义拒绝策略，只需要实现RejectedExecutionHander接口，自定义里面的rejectedExecution方法。 运行流程我们每个线程会被包装成Worker，线程池里面有一个HashSet存放Worker。 当有任务提交过来之后： 首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。 如果线程池中Worker的数量小于核心线程数，就会去创建一个新的线程，也就是招聘一个正式工让他执行任务。 如果Worker的数量大于或者等于核心线程数，就会把任务放到阻塞任务队列里面。 如果任务队列满了还有任务过来，如果临时工名额没有满（workerCount &lt; maximumPoolSize），就去招聘临时工让临时工执行任务。如果临时工名额都满了，触发任务拒绝策略。 总结而言，就是核心线程能干的事情尽量不去创建非核心线程，这是线程池很关键的一点。 有哪些线程池我有过四段工作经历，每段经历都有着精彩的故事。 SingleThreadExecutorSingleThreadExecutor是我加入的第一家线程池，这是一家创业公司，整个线程池就只有我一个线程。 所有的任务都由我干，而且任务队列是一个无界队列。就是说，打工的线程只有我一个，但是需求任务可以是无限多。 在需求任务很多的时候，经常出现任务处理不过来的情况，导致任务堆积，出现OOM。 但因为所有的活都是我干，没有繁琐的沟通成本，不需要处理线程同步的问题，这算是这种线程池的一个优点吧。 这种线程池适用于并发量不大且需要任务顺序执行的场景。 FixedThreadPool后来公司倒闭了，我又加入了一个叫FixedThreadPool的线程池。 FixedThreadPool和SingleThreadExecutor唯一不同的地方就是核心线程的数量，FixedThreadPool可以招收很多的打工线程。 在这里，我不再是孤军奋斗了，我有了一群共同打拼的小伙伴，大家一起完成任务，一起承担压力。 可这种线程池还是存在一个问题——任务队列是无界的，需求任务过多的话，还是会造成OOM。 这种线程池线程数固定，且不被回收，线程与线程池的生命周期同步的线程池，适用于任务量比较固定但耗时长的任务。 CachedThreadPool后来，为了离家更近，我离职了。加入了一家叫CachedThreadPool的线程池，进去之后，却发现这是一家外包公司。 这种线程池里面没有一个核心线程（正式工），一有需求就去招聘一个非核心线程（临时工）。 如果一个线程任务干完了之后，60秒之后没有新的任务就会被辞退。 这种线程池的任务队列采用的是SynchronousQueue，这个队列是无法插入任务的，一有任务就创建一个线程执行，如果并发高且任务耗时长，创建太多线程也是可能导致OOM的。所以CachedThreadPool比较适合任务量大但耗时少的任务。 ScheduleThreadPool经历了外面的风风雨雨，我觉得还是找份固定的工作比较可靠，于是我加入了一家叫做ScheduleThreadPool的国企。 在这里，工作比较的轻松，多数情况下，我只需要在固定的时间干固定的活。 任务忙不过来的时候，公司也会招聘一些临时工帮忙处理，临时工干完活就会被辞退。 综合来说，这类线程池适用于执行定时任务和具体固定周期的重复任务。由于采用的任务队列是DelayedWorkQueue无界队列，所以也是有OOM的风险的。 总结好了，关于线程的故事就告一段落了。关于线程池的应用实践，我们下次再聊。 文章开头的面试题在大部分在文中都能找到答案，对于没有提到的，这里做一个补充： 1. 线程池提交任务有哪几种方式？分别有什么区别？有execute和submit两种方式 execute只能提交Runnable类型的任务，无返回值。submit既可以提交Runnable类型的任务，也可以提交Callable类型的任务，会有一个类型为Future的返回值，但当任务类型为Runnable时，返回值为null。 execute在执行任务时，如果遇到异常会直接抛出，而submit不会直接抛出，只有在使用Future的get方法获取返回值时，才会抛出异常。 2. 线程池里面的线程执行异常了会怎么样？如果一个线程执行任务的过程中出现异常，那么这个线程对应的Worker会被移出线程池，该线程也会被销毁回收。 同时会通过指定的线程工厂创建一个线程，并封装成Worker放入线程池代替移除的Worker。 3. 核心线程能被回收吗？核心线程默认不会被回收。但是可以调用allowCoreThreadTimeOut让核心线程可以被回收。 需要注意的是，调用这个方法的线程池必须将keepAliveTime设置为大于0，否则会抛出异常。 4. 核心线程和非核心线程是如何区分的？核心线程和非核心线程是一个抽象概念，只是用于更好的表述线程池的运行逻辑，实际上都对应操作系统的osThread，都是重量级线程。 在新增Worker的时候，通过一个boolean表达是核心线程还是非核心线程，本质上两者没有什么不同。 5. 为什么阿里不允许使用 Executors 去创建线程池？FixedThreadPool 和 SingleThreadPool：允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 CachedThreadPool：允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 总结来说就是，使用Executors创建线程池会容易忽视线程池的一些属性，使用不当容易引起资源耗尽。 写在最后 这个世界上或许没有线程，又或许人人都是线程。 好了，今天的文章就到这里了。 最后，感谢你的阅读！ 我是CoderW，一个普通的程序员。 点个关注，我们下期再见！ 参考文章 https://mp.weixin.qq.com/s/baYuX8aCwQ9PP6k7TDl2Ww 《Java并发编程的艺术》 《深入理解Java虚拟机》","link":"/javathread/"},{"title":"用爬虫分析了2020年一年的热搜，我发现了什么？","text":"前言2020年是艰难的一年，但即使再难，也都过去了。 分析一下2020年的新闻热搜，可以大致了解网民都在关注什么。 微博热搜以娱乐为主，头条的热搜更偏向民生与时事。今天，我们先分析分析微博一整年的热搜。 数据抓取由于微博平台不能查看历史热搜，本文所有的数据都是从云合数据旗下的一个热搜榜抓取的，具体地址见文末。 抓取数据的代码是用Python写的，代码非常简单，就是模拟请求和数据统计两个部分。 抓取到了从2020年1月1日到2020年12月31日一共35901条数据，将抓取的数据存入Excel，数据格式如下图： 数据分析用pyecharts做可视化分析，先将所有的热搜数据按照热度做成一个词云。 “词云”是对海量文字内容中出现频率较高的视觉突出，即出现越多的“关键词”字体越大。这里用热度替代了出现次数 结合微博热搜话题搜索量TOP10，哪些热搜热度高就一目了然了。 罗志祥的分手引爆微博，两条热搜霸占全年热搜榜前二名，搜索指数加起来超过了5700万。要知道，鹿晗官宣和关晓彤在一起那一条热搜也只有1700多万搜索指数。 美国总统特朗普从看不起新冠，到最后夫妻双双确诊，打脸来的不要太快。“特朗普夫妇确诊新冠”的新闻也曾引爆微博甚至全球。 在前十榜单里面，“李文亮医生去世”和“李文亮仍在抢救”这两条热搜引人注目。 李文亮医生的事迹在当时引起了一阵轰动，一年的时间快要过去了，“李文亮”这个名字也慢慢不被人们提起，后人也许也不会知道这段故事。但人们不提，不代表忘记，互联网也是有记忆的，每当回忆起这次疫情，李文亮医生依旧站在那里。让我们向英雄致敬！ 热词回顾一年的热搜，和疫情相关的词汇出现的比较高频，“抗疫”成为了2020年中国甚至世界的主旋律。 2020年中美关系因美方一意孤行而比较紧张，加上美国疫情的不可控发展，“美国”和“特朗普”也频频登上热搜。 我还生成了“道歉”，“帅”，“结婚”，“分手”，“心疼”等关键字词云，大部分都是和娱乐圈相关的，今天你道歉，明天我发声。我的感觉就是，贵圈真乱。 人名出现次数排行榜统计了上热搜次数最多的前40个人。大部分都是娱乐圈的，其中周杰伦是榜中唯一一个没有开通微博的明星。 美国现总统特朗普和下任总统拜登因为选举和美国疫情不可控等因素频频上热搜，特朗普更是差不多平均一天上一次热搜。 获颁“共和国勋章”的敢医敢言的钟南山2020年上了196次热搜，从非典到新冠，攸关生命的大考，他从不缺位，向钟老致敬。 通过《陈情令》爆火的王一博和肖战，分别排在第四名和第六名。 有意思是，从2011年《宫》播出之后，杨幂每年上热搜次数就没有跌出过前10。 2020年，是直播带货蓬勃发展的一年，李佳琦和薇娅两个带货之王也频频登上热搜，甚至李佳琦以103次的成绩排到了第八名。 归国四子黄子韬、鹿晗、吴亦凡和张艺兴也依然保持热度，都有着比较靠前的排名。 2020年湖人队民宿科比坠机身亡，因此也上了69次热搜，R.I.P。 不开通微博的周董周杰伦，凭借自己的实力和强大的粉丝群体，强行上了59次热搜，是为数不多不靠炒作就能登上这个榜单的明星了。 最近一个月才大火的丁真，就以47次热搜的成绩登上排行榜，同时丁真也是12月上热搜次数最多的人。 总结 2020年微博热搜主旋律——抗疫 2020年上微博热搜次数最多的人——特朗普 2020年上微博热搜次数最多的娱乐明星——易烊千玺 2020年热度最高的微博热搜——罗志祥周扬青分手 以上所有的数据都基于热搜平台，一切信息都可以在平台查询。 写到这里，如果你问“买热搜”真的存在吗？ 我会告诉你，“买热搜”真的存在。我分析了几年的微博热搜数据，确实发现了一些问题，有些热搜非常莫名其妙，热度来得快去的也快，再结合一下其他平台的数据就能容易分析出这个热搜的真实性了。 但如果你问我有哪些明星买了热搜，我不能告诉你，为什么呢？因为我告诉你我的号就没了。 如果你实在有兴趣，公众号后台回复“热搜”，我会给你一份2020一整年的微博热搜数据Excel，你可以自己去慢慢分析。 写在最后以上所有的数据都基于热搜平台，一切信息都可以在平台查询。 本人才疏学浅，如有错误欢迎指出！ 最后，感谢您的阅读。 您的点赞和转发都是对我最大的支持，十分欢迎并感谢您的关注。 本文所有的资料和源码关注公众号‘CoderW’回复‘热搜’即可获取 热搜平台：https://www.enlightent.cn/research/rank/weiboSearchRank 参考文章: https://mp.weixin.qq.com/s/BD1rqPCQvhYP4i4bef_BAg。","link":"/resou/"},{"title":"深入汇编指令解析Java关键字volatile","text":"volatile是什么volatile关键字是Java提供的一种轻量级同步机制。它能够保证可见性和有序性，但是不能保证原子性 可见性对于volatile的可见性，先看看这段代码的执行 flag默认为true 创建一个线程A去判断flag是否为true，如果为true循环执行i++操作 两秒后，创建另一个线程B将flag修改为false 线程A没有感知到flag已经被修改成false了，不能跳出循环 这相当于啥呢？相当于你的女神和你说，你好好努力，年薪百万了就嫁给你，你听了之后，努力赚钱。3年之后，你年薪百万了，回去找你女神，结果发现你女神结婚了，她结婚的消息根本没有告诉你！难不难受？ 女神结婚可以不告诉你，可是Java代码中的属性都是存在内存中，一个线程的修改为什么另一个线程为什么不可见呢？这就不得不提到Java中的内存模型了，Java中的内存模型，简称JMM，JMM定义了线程和主内存之间的抽象关系，定义了线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量的副本，它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。 注意！JMM是一个屏蔽了不同操作系统架构的差异的抽象概念，只是一组Java规范。 了解了JMM，现在我们再回顾一下文章开头的那段代码，为什么线程B修改了flag线程A看到的还是原来的值呢？ 因为线程A复制了一份刚开始的flage=true到本地内存，之后线程A使用的flag都是这个复制到本地内存的flag。 线程B修改了flag之后，将flag的值刷新到主内存，此时主内存的flag值变成了false。 线程A是不知道线程B修改了flag，一直用的是本地内存的flag = true。 那么，如何才能让线程A知道flag被修改了呢？或者说怎么让线程A本地内存中缓存的flag无效，实现线程间可见呢？用volatile修饰flag就可以做到: 我们可以看到，用volatile修饰flag之后，线程B修改flag之后线程A是能感知到的，说明了volatile保证了线程同步之间的可见性。 重排序在阐述volatile有序性之前，需要先补充一些关于重排序的知识。 重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。 为什么要有重排序呢？简单来说，就是为了提升执行效率。为什么能提升执行效率呢？我们看下面这个例子： 可以看到重排序之后CPU实际执行省略了一个读取和写回的操作，也就间接的提升了执行效率。 有一点必须强调的是，上图的例子只是为了让读者更好的理解为什么重排序能提升执行效率，实际上Java里面的重排序并不是基于代码级别的，从代码到CPU执行之间还有很多个阶段，CPU底层还有一些优化，实际上的执行流程可能并不是上图的说的那样。不必过于纠结于此。 重排序可以提高程序的运行效率，但是必须遵循as-if-serial语义。as-if-serial语义是什么呢？简单来说，就是不管你怎么重排序，你必须保证不管怎么重排序，单线程下程序的执行结果不能被改变。 有序性上面我们已经介绍了Java有重排序情况，现在我们再来聊一聊volatile的有序性。 先看一个经典的面试题：为什么DDL（double check lock）单例模式需要加volatile关键字？ 因为singleton = new Singleton()不是一个原子操作，大概要经过这几个步骤： 分配一块内存空间 调用构造器，初始化实例 singleton指向分配的内存空间 实际执行的时候，可能发生重排序，导致实际执行步骤是这样的： 申请一块内存空间 singleton指向分配的内存空间 调用构造器，初始化实例 在singleton指向分配的内存空间之后，singleton就不为空了。但是在没有调用构造器初始化实例之前，这个对象还处于半初始化状态，在这个状态下，实例的属性都还是默认属性，这个时候如果有另一个线程调用getSingleton()方法时，会拿到这个半初始化的对象，导致出错。 而加volatile修饰之后，就会禁止重排序，这样就能保证在对象初始化完了之后才把singleton指向分配的内存空间，杜绝了一些不可控错误的产生。volatile提供了happens-before保证，对volatile变量的写入happens-before所有其他线程后续对的读操作。 原理从上面的DDL单例用例来看，在并发情况下，重排序的存在会导致一些未知的错误。而加上volatile之后会防止重排序，那volatile是如何禁止重排序呢？ 为了实现volatile的内存语义，JMM会限制特定类型的编译器和处理器重排序，JMM会针对编译器制定volatile重排序规则表： 总结来说就是： 第二个操作是volatile写，不管第一个操作是什么都不会重排序 第一个操作是volatile读，不管第二个操作是什么都不会重排序 第一个操作是volatile写，第二个操作是volatile读，也不会发生重排序 如何保证这些操作不会发送重排序呢？就是通过插入内存屏障保证的，JMM层面的内存屏障分为读（load）屏障和写（Store）屏障，排列组合就有了四种屏障。对于volatile操作，JMM内存屏障插入策略： 在每个volatile写操作的前面插入一个StoreStore屏障 在每个volatile写操作的后面插入一个StoreLoad屏障 在每个volatile读操作的后面插入一个LoadLoad屏障 在每个volatile读操作的后面插入一个LoadStore屏障 上面的屏障都是JMM规范级别的，意思是，按照这个规范写JDK能保证volatile修饰的内存区域的操作不会发送重排序。 在硬件层面上，也提供了一系列的内存屏障来提供一致性的能力。拿X86平台来说，主要提供了这几种内存屏障指令： lfence指令：在lfence指令前的读操作当必须在lfence指令后的读操作前完成，类似于读屏障 sfence指令：在sfence指令前的写操作当必须在sfence指令后的写操作前完成，类似于写屏障 mfence指令： 在mfence指令前的读写操作当必须在mfence指令后的读写操作前完成，类似读写屏障。 JMM规范需要加这么多内存屏障，但实际情况并不需要加这么多内存屏障。以我们常见的X86处理器为例，X86处理器不会对读-读、读-写和写-写操作做重排序，会省略掉这3种操作类型对应的内存屏障，仅会对写-读操作做重排序。所以volatile写-读操作只需要在volatile写后插入StoreLoad屏障。在《The JSR-133 Cookbook for Compiler Writers》中，也很明确的指出了这一点： 而在x86处理器中，有三种方法可以实现实现StoreLoad屏障的效果，分别为： mfence指令：上文提到过，能实现全能型屏障，具备lfence和sfence的能力。 cpuid指令：cpuid操作码是一个面向x86架构的处理器补充指令，它的名称派生自CPU识别，作用是允许软件发现处理器的详细信息。 lock指令前缀：总线锁。lock前缀只能加在一些特殊的指令前面。 实际上HotSpot关于volatile的实现就是使用的lock指令，只在volatile标记的地方加上带lock前缀指令操作，并没有参照JMM规范的屏障设计而使用对应的mfence指令。 加上-XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XcompJVM参数再次执行main方法，在打印的汇编码中，我们也可以看到有一个lock addl $0x0,(%rsp)的操作。 在源码中也可以得到验证： lock addl $0x0,(%rsp)后面的addl $0x0,(%rsp)其实是一个空操作。add是加的意思，0x0是16进制的0，rsp是一种类型寄存器，合起来就是把寄存器的值加0，加0是不是等于什么都没有做？这段汇编码仅仅是lock指令的一个载体而已。其实上文也有提到过，lock前缀只能加在一些特殊的指令前面，add就是其中一个指令。 至于Hotspot为什么要使用lock指令而不是mfence指令，按照我的理解，其实就是省事，实现起来简单。因为lock功能过于强大，不需要有太多的考虑。而且lock指令优先锁缓存行，在性能上，lock指令也没有想象中的那么差，mfence指令更没有想象中的好。所以，使用lock是一个性价比非常高的一个选择。而且，lock也有对可见性的语义说明。 在《IA-32架构软件开发人员手册》的指令表中找到lock： 我不打算在这里深入阐述lock指令的实现原理和细节，这很容易陷入堆砌技术术语中，而且也超出了本文的范围，有兴趣的可以去看看《IA-32架构软件开发人员手册》。 我们只需要知道lock的这几个作用就可以了： 确保后续指令执行的原子性。在Pentium及之前的处理器中，带有lock前缀的指令在执行期间会锁住总线，使得其它处理器暂时无法通过总线访问内存，很显然，这个开销很大。在新的处理器中，Intel使用缓存锁定来保证指令执行的原子性，缓存锁定将大大降低lock前缀指令的执行开销。 禁止该指令与前面和后面的读写指令重排序。 把写缓冲区的所有数据刷新到内存中。 总结来说，就是lock指令既保证了可见性也保证了原子性。 重要的事情再说一遍，是lock指令既保证了可见性也保证了原子性，和什么缓冲一致性协议啊，MESI什么的没有一点关系。 为了不让你把缓存一致性协议和JMM混淆，在前面的文章中，我特意没有提到过缓存一致性协议，因为这两者本不是一个维度的东西，存在的意义也不一样，这一部分，我们下次再聊。 总结全文重点是围绕volatile的可见性和有序性展开的，其中花了不少的部分篇幅描述了一些计算机底层的概念，对于读者来说可能过于无趣，但如果你能认真看完，我相信你或多或少也会有一点收获。 不去深究，volatile只是一个普通的关键字。深入探讨，你会发现volatile是一个非常重要的知识点。volatile能将软件和硬件结合起来，想要彻底弄懂，需要深入到计算机的最底层。但如果你做到了。你对Java的认知一定会有进一步的提升。 只把眼光放在Java语言，似乎显得非常局限。发散到其他语言，C语言，C++里面也都有volatile关键字。我没有看过C语言，C++里面volatile关键字是如何实现的，但我相信底层的原理一定是相通的。 写在最后本着对每一篇发出去的文章负责的原则，文中涉及知识理论，我都会尽量在官方文档和权威书籍找到并加以验证。但即使这样，我也不能保证文中每个点都是正确的，如果你发现错误之处，欢迎指出，我会对其修正。 创作不易，你的正反馈对我来说非常重要！点个赞，点个再看，点个关注甚至评论区发送一条666都是对我最大的支持！ 我是CoderW，一个普通的程序员。 谢谢你的阅读，我们下期再见！ 个人公众号“CoderW”，欢迎并十分感谢你的关注 参考资料 JSR-133: http://gee.cs.oswego.edu/dl/jmm/cookbook.html 《Java并发编程的艺术》 《深入理解Java虚拟机》第三版 《IA-32+架构软件开发人员手册》","link":"/volatile/"},{"title":"来自未来的技术——ZGC垃圾回收器","text":"ZGC介绍ZGC（The Z Garbage Collector）是JDK 11中推出的一款追求极致低延迟的实验性质的垃圾收集器，它曾经设计目标包括： 停顿时间不超过10ms； 停顿时间不会随着堆的大小，或者活跃对象的大小而增加； 支持8MB~4TB级别的堆（未来支持16TB）。 当初，提出这个目标的时候，有很多人都觉得设计者在吹牛逼。 但今天看来，这些“吹下的牛逼”都在一个个被实现。 基于最新的JDK15来看，“停顿时间不超过10ms”和“支持16TB的堆”这两个目标已经实现，并且官方明确指出JDK15中的ZGC不再是实验性质的垃圾收集器，且建议投入生产了。 本文会从ZGC的设计思路出发，讲清楚为何ZGC能在低延时场景中的应用中有着如此卓越的表现。 核心技术多重映射为了能更好的理解ZGC的内存管理，我们先看一下这个例子： 你在你爸爸妈妈眼中是儿子，在你女朋友眼中是男朋友。在全世界人面前就是最帅的人。你还有一个名字，但名字也只是你的一个代号，并不是你本人。将这个关系画一张映射图表示： 在你爸爸的眼中，你就是儿子； 在你女朋友的眼中，你就说男朋友； 站在全世界角度来看，你就说世界上最帅的人； 假如你的名字是全世界唯一的，通过“你的名字”、“你爸爸的儿子”、“你女朋友的男朋友”，“世界上最帅的人”最后定位到的都是你本人。 现在我们再来看看ZGC的内存管理。 ZGC为了能高效、灵活地管理内存，实现了两级内存管理：虚拟内存和物理内存，并且实现了物理内存和虚拟内存的映射关系。这和操作系统中虚拟地址和物理地址设计思路基本一致。 当应用程序创建对象时，首先在堆空间申请一个虚拟地址，ZGC同时会为该对象在Marked0、Marked1和Remapped三个视图空间分别申请一个虚拟地址，且这三个虚拟地址对应同一个物理地址。 图中的Marked0、Marked1和Remapped三个视图是什么意思呢？ 对照上面的例子，这三个视图分别对应的就是”你爸爸眼中”，“你女朋友的眼中”，“全世界人眼中”。 而三个视图里面的地址，都是虚拟地址，对应的是“你爸爸眼中的儿子”，“你女朋友眼中的男朋友”…… 最后，这些虚地址都能定位到一个物理地址，这个物理地址对应上面例子中的“你本人”。 用一段简单的Java代码表示就是这样的： 在ZGC中这三个空间在同一时间点有且仅有一个空间有效。 为什么这么设计呢？这就是ZGC的高明之处，利用虚拟空间换时间，这三个空间的切换是由垃圾回收的不同阶段触发的，通过限定三个空间在同一时间点有且仅有一个空间有效高效的完成GC过程的并发操作，具体实现会后面讲ZGC并发处理算法的部分再详细描述。 染色指针在讲ZGC并发处理算法之前，还需要补充一个知识点——染色指针。 我们都知道，之前的垃圾收集器都是把GC信息（标记信息、GC分代年龄..）存在对象头的Mark Word里。举个例子： 如果某个人是个垃圾人，就在这个人的头上盖一个“垃圾”的章；如果这个人不是垃圾了，就把这个人头上的“垃圾”印章洗掉。 而ZGC是这样做的： 如果某个人是垃圾人。就在这个人的身份证信息里面标注这个人是个垃圾，以后不管这个人在哪刷身份证，别人都知道他是个垃圾人了。也许哪一天，这个人醒悟了不再是垃圾人了，就把这个人身份证里面的“垃圾”标志去掉。 在这例子中，“这个人”就是一个对象，而“身份证”就是指向这个对象的指针。 ZGC将信息存储在指针中，这种技术有一个高大上的名字——染色指针（Colored Pointer）。 在64位的机器中，对象指针是64位的。 ZGC使用64位地址空间的第0~43位存储对象地址，2^44 = 16TB，所以ZGC最大支持16TB的堆。 而第44~47位作为颜色标志位，Marked0、Marked1和Remapped代表三个视图标志位，Finalizable表示这个对象只能通过finalizer才能访问。 第48~63位固定为0没有利用。 读屏障读屏障是JVM向应用代码插入一小段代码的技术。当应用线程从堆中读取对象引用时，就会执行这段代码。千万不要把这个读屏障和Java内存模型里面的读屏障搞混了，两者根本不是同一个东西，ZGC中的读屏障更像是一种AOP技术，在字节码层面或者编译代码层面给读操作增加一个额外的处理。 读屏障实例： 123456Object o = obj.FieldA // 从堆中读取对象引用，需要加入读屏障&lt;load barrier needed here&gt; Object p = o // 无需加入读屏障，因为不是从堆中读取引用o.dosomething() // 无需加入读屏障，因为不是从堆中读取引用int i = obj.FieldB // 无需加入读屏障，因为不是对象引用 ZGC中读屏障的代码作用： GC线程和应用线程是并发执行的，所以存在应用线程去A对象内部的引用所指向的对象B的时候，这个对象B正在被GC线程移动或者其他操作，加上读屏障之后，应用线程会去探测对象B是否被GC线程操作，然后等待操作完成再读取对象，确保数据的准确性。具体的探测和操作步骤如下： 这样会影响程序的性能吗？ 会。据测试，最多百分之4的性能损耗。但这是ZGC并发转移的基础，为了降低STW，设计者认为这点牺牲是可接受的。 ZGC并发处理算法ZGC并发处理算法利用全局空间视图的切换和对象地址视图的切换，结合SATB算法实现了高效的并发。 以上所有的铺垫，都是为了讲清楚ZGC的并发处理算法，在一些博文上，都说染色指针和读屏障是ZGC的核心，但都没有讲清楚两者是如何在算法里面被利用的，我认为，ZGC的并发处理算法才是ZGC的核心，染色指针和读屏障只不过是为算法服务而已。 ZGC的并发处理算法三个阶段的全局视图切换如下： 初始化阶段：ZGC初始化之后，整个内存空间的地址视图被设置为Remapped 标记阶段：当进入标记阶段时的视图转变为Marked0（以下皆简称M0）或者Marked1（以下皆简称M1） 转移阶段：从标记阶段结束进入转移阶段时的视图再次设置为Remapped 标记阶段标记阶段全局视图切换到M0视图。因为应用程序和标记线程并发执行，那么对象的访问可能来自标记线程和应用程序线程。 在标记阶段结束之后，对象的地址视图要么是M0，要么是Remapped。 如果对象的地址视图是M0，说明对象是活跃的； 如果对象的地址视图是Remapped，说明对象是不活跃的，即对象所使用的内存可以被回收。 当标记阶段结束后，ZGC会把所有活跃对象的地址存到对象活跃信息表，活跃对象的地址视图都是M0。 转移阶段转移阶段切换到Remapped视图。因为应用程序和转移线程也是并发执行，那么对象的访问可能来自转移线程和应用程序线程。 至此，ZGC的一个垃圾回收周期中，并发标记和并发转移就结束了。 为何要设计M0和M1我们提到在标记阶段存在两个地址视图M0和M1，上面的算法过程显示只用到了一个地址视图，为什么设计成两个？简单地说是为了区别前一次标记和当前标记。 ZGC是按照页面进行部分内存垃圾回收的，也就是说当对象所在的页面需要回收时，页面里面的对象需要被转移，如果页面不需要转移，页面里面的对象也就不需要转移。 如图，这个对象在第二次GC周期开始的时候，地址视图还是M0。如果第二次GC的标记阶段还切到M0视图的话，就不能区分出对象是活跃的，还是上一次垃圾回收标记过的。这个时候，第二次GC周期的标记阶段切到M1视图的话就可以区分了，此时这3个地址视图代表的含义是： M1：本次垃圾回收中识别的活跃对象。 M0：前一次垃圾回收的标记阶段被标记过的活跃对象，对象在转移阶段未被转移，但是在本次垃圾回收中被识别为不活跃对象。 Remapped：前一次垃圾回收的转移阶段发生转移的对象或者是被应用程序线程访问的对象，但是在本次垃圾回收中被识别为不活跃对象。 现在，我们可以回答“使用地址视图和染色指针有什么好处”这个问题了 使用地址视图和染色指针可以加快标记和转移的速度。以前的垃圾回收器通过修改对象头的标记位来标记GC信息，这是有内存存取访问的，而ZGC通过地址视图和染色指针技术，无需任何对象访问，只需要设置地址中对应的标志位即可。这就是ZGC在标记和转移阶段速度更快的原因。 当GC信息不再存储在对象头上时而存在引用指针上时，当确定一个对象已经无用的时候，可以立即重用对应的内存空间，这是把GC信息放到对象头所做不到的。 ZGC步骤ZGC采用的是标记-复制算法，标记、转移和重定位阶段几乎都是并发的，ZGC垃圾回收周期如下图所示： ZGC只有三个STW阶段：初始标记，再标记，初始转移。 其中，初始标记和初始转移分别都只需要扫描所有GC Roots，其处理时间和GC Roots的数量成正比，一般情况耗时非常短； 再标记阶段STW时间很短，最多1ms，超过1ms则再次进入并发标记阶段。即，ZGC几乎所有暂停都只依赖于GC Roots集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。与ZGC对比，G1的转移阶段完全STW的，且停顿时间随存活对象的大小增加而增加。 ZGC的发展ZGC诞生于JDK11，经过不断的完善，JDK15中的ZGC已经不再是实验性质的了。 从只支持Linux/x64，到现在支持多平台；从不支持指针压缩，到支持压缩类指针….. 在JDK16，ZGC将支持并发线程栈扫描（Concurrent Thread Stack Scanning），根据SPECjbb2015测试结果，实现并发线程栈扫描之后，ZGC的STW时间又能降低一个数量级，停顿时间将进入毫秒时代。 ZGC已然是一款优秀的垃圾收集器了，它借鉴了Pauseless GC，也似乎在朝着C4 GC的方向发展——引入分代思想。 Oracle的努力，让我们开发者看到了商用级别的GC“飞入寻常百姓家”的希望，随着JDK的发展，我相信在未来的某一天，JVM调优这种反人类的操作将不复存在，底层的GC会自适应各种情况自动优化。 ZGC确实是Java的最前沿的技术，但在G1都没有普及的今天，谈论ZGC似乎为时过早。但也许我们探讨的不是ZGC，而是ZGC背后的设计思路。 希望你能有所收获！ 写在最后为了对每一篇发出去的文章负责，力求准确，我一般是参考官方文档和业界权威的书籍，有些时候，还需要看一些论文，看一部分源代码。而官方文档和论文一般都是英文，对于一个英语四级只考了456分的人来说，非常艰难，整个过程都是谷歌翻译和有道词典陪伴着我的。因为一些专业术语翻译的不够准确，还需要英文和翻译对照慢慢理解。 但即使这样，也难免会有纰漏，如果你发现了，欢迎提出，我会对其修正。 你的正反馈对我来说非常重要，点个赞，点个关注都是对我最大的支持！ 如果你有什么想和我交流的，可以关注我的微信公众号“CoderW”，非常欢迎并感谢您的关注！ 谢谢您的阅读，我们下期再见！ 参考资料 https://mp.weixin.qq.com/s/ag5u2EPObx7bZr7hkcrOTg 《新一代垃圾回收器ZGC设计与实现》","link":"/zgc/"},{"title":"ThreadLocal到底是个啥？","text":"1.ThreadLocal是什么 ThreadLocal，即线程变量，是一个以ThreadLocal对象为键、任意对象为值的存储结构。这个结构被附带在线程上，也就是说一个线程可以根据一个ThreadLocal对象查询到绑定在这个线程上的一个值。 ——《Java并发编程艺术》 首先，我们站在人类认知事物的角度，按照下面这张图的思路出发： 首先看到ThreadLocal，可以拆成Thread+Local Thread—线程；local—本地的，局域的。 拼在一起就是线程局域的。线程私有的。 OK，如果你想到了这一点，其实你已经知道了ThreadLocal的最大特点——线程私有。这种理解是对的，ThreadLocal类顾名思义可以理解为线程本地变量。也就是说如果定义了一个ThreadLocal，每个线程往这个ThreadLocal中读写是线程隔离，互相之间不会影响的。它提供了一种将可变数据通过每个线程有自己的独立副本从而实现线程封闭的机制。 2.ThreadLocal怎么用下面是一段很简单的代码，展示了ThreadLocal的基本用法： CAR_HOUSEKEEPER是一个ThreadLocal对象，以下简称车辆管家 主线程中创建了两个线程：富商A线程和富商B线程，以下简称A和B。 A把自己买的“兰博基尼”交给车辆管家 B也把自己买的“兰博基尼”交给车辆管家 A需要用车的时候，车辆管家给他的是A的兰博基尼 B需要用车的时候，车辆管家给他的是B的兰博基尼 A把车卖了，就拿不到车了 ThreadLocal三个重要方法： set：存数据（叫管家停车） get：取数据（叫管家取车） remove：删除数据（叫管家卖车） 3.ThreadLocal原理错误的认识看完ThreadLocal的使用，聪明的你肯定会在脑海里想，怎么能做到这样呢？于是乎，在你的脑海里出来了下面这一张错误的结构图： 那么为什么不这样设计呢？或者说这样设计有什么缺点呢？ 如果按照上面这种设计的话，我们打个比方： 你是一位成功的商业人士，非常有钱，家里有一栋一万平的别墅。于是你雇了两个管家。一个管家帮你管理跑车，一个管家帮你管理自行车，这是大前提。 今天你买了一辆兰博基尼，你把钥匙交给第一个管家，第一个管家把车停到他自己家的停车场去了； 第二天你又买了一辆自行车，你把自行车交给第二个管家，第二个管家把车骑到他自己家的停车场去了； 当你需要用兰博基尼的时候，第一个管家去他家里帮你把车开来。 当你需要骑自行车的时候，第二个管家去他家里帮你把车骑来。 把上面的例子抽象一下，Thread对应你，ThreadLocal对应管家，ThreadLocal里面的Map对应管家的车库。你是不是会发现这样的模式非常不合理？我买的兰博基尼明明是我用的，为什么不停在我的家里？管家本来只需要停车，现在却要在自己家里建一个车库。是不是莫名其妙？ 实际的设计还是上面那个例子，你觉得非常不合理，你决定这样做： 今天你买了一辆兰博基尼，你把钥匙交给第一个管家，管家把车停到你家车库的某个地方； 没有车库的话，管家帮你招人建一个车库，然后把车停进去。 第二天你又买了一辆自行车，你把自行车交给第二个管家，管家把车放到到你家车库的某个地方； 而你只需要关注谈商业合作，处理一些重要的事情。 当你需要用兰博基尼的时候，只需要叫第一个管家把车从你的车库开来就行。 当你需要骑自行车的时候，只需要叫第二个管家把自行车从你家车库骑过来就行。 显然，这样就变得合理多了。 Josh Bloch和Doug Lea两位大师受到了你的启发（开个玩笑），就设计出了我们现在用到的ThreadLocal。 Thread对应你，ThreadLocal对应管家，你家车库对应Thread中的一个Map。不同种类型的车对应不同的类，但是这些不同类型的车都属于车（Object）。 我们在上面的例子上，加一个条件——允许管家可以打多份工。可以得到了下面简图： 我们抽象一下，结合代码，看看调用set()方法的时候，到底干了什么呢？我们看一下动态图： 从上面的动图，我们可以很清楚的看到，在调用ThreadLocal的set()方法时，数据是如何存储的。当然，上面的图不是内存分布图，只是一个简图，不够严谨，只是为了让你了解基本的原理。 可以总结成一句话： 每个线程内部都有个map，调用ThreadLocal.set(object)方法时，把这个ThreadLocal对象作为key,object作为值存到了这个内部map里面。 我们用一张图翻译一下这句话，得到的就是ThreadLocal和Thread之间的关系： 源码分析以下的部分会非常非常干，需要有点GC的基础，不过，只需要一点点就行。 ThreadLocal结构ThreadLocal的API非常的简单，ThreadLocal对外就提供了五个方法： ThreadLocal()：构造方法 withInitial()：静态方法，通过这个方法创建ThreadLocal可以重写initialValue方法（返回当前线程的这个线程私有变量的“初始值”），自己设置默认值 get()：获得此线程私有变量的当前线程副本中的值 set(T)：设置此线程私有变量的当前线程副本中的值 remove()：删除此线程私有变量的当前线程副本中的值 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ThreadLocal&lt;T&gt; { /** * 创建一个线程局部变量。 * 变量的初始值是通过调用Supplier函数的get方法来确定的。 * SuppliedThreadLocal是ThreadLocal的一个扩展，它是一个函数 */ public static &lt;S&gt; ThreadLocal&lt;S&gt; withInitial(Supplier&lt;? extends S&gt; supplier) { return new SuppliedThreadLocal&lt;&gt;(supplier); } /** * 设置此线程私有变量的当前线程副本中的值 */ public void set(T value) { //获取当前线程 Thread t = Thread.currentThread(); //获取当前线程的threadLocals（ThreadLocalMap） ThreadLocalMap map = getMap(t); //如果threadLocals已经被初始化了，把值放进去；如果不存在，先初始化再把值放进去 if (map != null) map.set(this, value); else createMap(t, value); } /** * 获得此线程私有变量的当前线程副本中的值 */ public T get() { //获取当前线程 Thread t = Thread.currentThread(); //获取当前线程的threadLocals（ThreadLocalMap） ThreadLocalMap map = getMap(t); if (map != null) { //从threadLocals获取节点（Entry） ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { T result = (T)e.value; return result; } } //如果map为空，返回的初始值，如果没有重写initialValue方法，返回的是null return setInitialValue(); } /** * 删除此线程私有变量的当前线程副本中的值 */ public void remove() { ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); }} 上面一段代码，简化了一些细节，把ThreadLocal对外提供的重要的四个方法的源码列了出来，你只需要知道Thread.currentThread()和this关键字是干什么的，就能非常容易的理解了。 ThreadLocalMap结构ThreadLocalMap是ThreadLocal的一个静态内部类。里面的核心是一个Entry数组，Entry继承了WeakReference，在创建Entry的时候，将ThreadLocal对象设置成了弱引用。 注意，ThreadLocalMap虽然是ThreadLocal里面的一个静态内部类，但是它的实例是放在Thread里面的，这个地方一定要分清楚，前面没有提及就是怕大家混淆。 123456789101112131415161718192021222324252627282930static class ThreadLocalMap { /** * 初始容量，默认为16，必须为2的幂 */ private static final int INITIAL_CAPACITY = 16; /** * 表里entry的个数 */ private int size = 0; /** * Entry表，大小必须为2的幂 */ private Entry[] table; /** * Entry继承了WeakReference * Entry的构造方法中调用了super(k)，将ThreadLocal对象设置成了弱引用 */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { /** value就是和ThreadLocal绑定的，为实际放入的值 */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; } }} 知道了ThreadLocalMap的机构，我们用一张时序图表示调用ThreadLocal的get()方法的流程（其中的create表示调用默认的构造方法）： 什么是弱引用Java存在四种引用关系（如下表）。如果一个对象存在一个弱引用，那么他会在下一次GC的时候被回收，至于为什么，是怎么做到的，本文不做过多的分析。我们只需要知道它的一个最大特点——下一次GC被回收。 引用类型 回收时间 应用场景 强引用 一直存在 一般对象 软引用 内存不足会被回收 缓存 弱引用 下一次GC被回收 缓存，ThreadLocal 虚引用 虚引用必须要和引用队列一起使用，他的get方法永远返回null JVM堆外内存管理 弱引用的例子： 为什么要用弱引用我们假设用强引用，会出现什么问题呢？我们看一下这张动态图： 从上面的图我们可以看出，如果不用弱引用而用强引用的话： 当ThreadLocal对象不用的时候，将他的引用设置成null，引用所指的堆中的ThreadLocal是没有办法被回收的，永远存在一条ThreadRef-&gt;Thread-&gt;ThreadLocalMap-&gt;Entry-&gt;ThreadLocal的强引用链。导致这一部分的内存无法被回收，造成内存泄漏。 而弱引用是Java中四档引用的第三档，比软引用更加弱一些，如果一个对象没有强引用链可达，那么一般活不过下一次GC。当某个ThreadLocal已经没有强引用可达，则随着它被垃圾回收，在ThreadLocalMap里对应的Entry的键值会失效，这为ThreadLocalMap本身的垃圾清理提供了便利。 InheritableThreadLocalInheritableThreadLocal继承了ThreadLocal，在ThreadLocal的基础上做了一点扩展，提供了一种父子线程之间的数据共享机制，在这里不多做介绍，有兴趣的可以去了解一下。 4.ThreadLocal内存泄漏所谓的内存泄漏，就是程序申请的内存无法被JVM回收。 什么情况下会内存泄漏前面已经说了ThreadLocal怎么用弱引用避免了内存泄漏。但是，如果使用不当，还是会出现内存泄漏的。注意，这是两个问题。那么，怎么样使用会造成内存泄漏呢？ 我们把JVM的最大堆设置成100MB，运行下面的代码，用JProfiler查看内存使用情况，发现内存使用不断增大，直到抛出java.lang.OutOfMemoryError: Java heap space也就是OOM异常。 我们分析一下代码： 创建了一个核心线程数和最大线程数为5的线程池，这个保证了线程池里面随时都有5个线程在运行 模拟50个任务，每隔2秒往线程池里面加一个任务 任务：创建一个User对象user，给user的threadLocal赋值一个新创建的ThreadLocal对象，往这个ThreadLocal对象里面加一个5MB的Memory对象。 我们画出内存分配图： 图中模拟了内存的分布和GC之后部分内存的回收，我们可以清楚的看到： ThreadLocal对象存在两个引用，实现代表强引用，虚线代表弱引用。 强引用因为引用对象被回收了引用不存在了 虚引用是不能阻止GC的回收的 最终Entry的key最终指向的是null，而value指向的还是占用5MB内存空间的Memory对象。 这个时候，存在一条ThreadRef-&gt;Thread-&gt;ThreadLocalMap-&gt;Entry-&gt;Memory的强引用链，导致Memory无法被回收，造成内存泄漏，最终导致OOM。 通过上面的内存分配图，我们不能得出： 如果线程运行完任务就结束了，ThreadRef-&gt;Thread-&gt;ThreadLocalMap-&gt;Entry-&gt;Memory这条引用链就不存在了，就不存在内存泄漏的问题了。 但是现在的Java应用，为了节省开销，大部分都会采用线程池的模式。为了不造成内存泄漏，最简单有效的方法是使用后调用remove()方法将其移除。 5.ThreadLocal的应用场景 Spring事务 APM的traceId Session管理 JDK7使用SimpleDateFormat 数据库的连接池 …… 总之，有以下两个特点的地方，都可以用到ThreadLocal： 方法调用链路很长，很多地方都需要用到这个参数，避免不必要的参数传递 要求线程间数据隔离 6.总结本博文重点介绍了ThreadLocal中ThreadLocalMap的大致实现原理以及ThreadLocal内存泄露的问题。旨在让大家对ThreadLocal能有一些新的理解。 文章省略了一些细节的问题，对于ThreadLocalMap的算法实现和它用线性探测法来解决散列冲突没有做介绍。因为我认为关于散列冲突的问题，是需要专门写一篇文章来介绍的。其中将数组当做环来用的思想也非常经典。说到环，又不得不提Disruptor和一致性hash，这一些经典的设计，希望以后能慢慢的给大家分享。 作为Josh Bloch和Doug Lea两位大师之作，ThreadLocal本身实现的算法与技巧还是很优雅的，非常值得一看。这一部分的代码是我在JDK中最喜欢的一段代码，每次看到，都是称赞不已。 写在最后文笔虽烂，但喜欢分享，有时分享技术，有时分享生活。 我是CoderWang，一个Java程序员。 我们下期再见！ 如果可以，点赞、加关注，谢谢你！ 更多精彩微信公众号搜索“CoderW”，我们一起进步！","link":"/threadLocal/"}],"tags":[{"name":"程序人生","slug":"程序人生","link":"/tags/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"数据分析","slug":"数据分析","link":"/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"categories":[{"name":"程序人生","slug":"程序人生","link":"/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"JVM","slug":"JVM","link":"/categories/JVM/"}]}